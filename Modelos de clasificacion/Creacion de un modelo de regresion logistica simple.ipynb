{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion de un modelo de regresion logistica simple\n",
    "\n",
    "## Data visualization\n",
    "\n",
    "Comencemos este ejercicio cargando y examinando nuestros datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/avalanche.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('avalanche.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploración de datos\n",
    "\n",
    "El campo de avalanchas es nuestro objetivo. Un valor de 1 significa que ocurrió una avalancha en las condiciones descritas por las características, mientras que un valor de 0 significa que no ocurrió ninguna avalancha. Dado que nuestros objetivos solo pueden ser 0 o 1, llamamos a esto un modelo de clasificación binaria.\n",
    "\n",
    "Ahora, vamos a graficar las relaciones entre cada característica y los valores objetivo. Eso nos ayuda a comprender qué características son más propensas a influir en los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"surface_hoar\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"fresh_thickness\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"weak_layers\", show=True)\n",
    "graphing.box_and_whisker(dataset, label_x=\"avalanche\", label_y=\"no_visitors\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podemos observar que:\n",
    "\n",
    "* Para fresh_thickness, los resultados son muy similares. Esto significa que las variaciones en sus valores no están fuertemente correlacionadas con los resultados.\n",
    "\n",
    "* Las variaciones en los valores de weak_layers y no_visitors parecen estar correlacionadas con un mayor número de resultados de avalanchas, por lo que debemos asignar más importancia a estas características.\n",
    "\n",
    "Las diferencias entre los días con avalanchas y los días sin avalanchas son pequeñas y no hay un factor claro que las explique. Weak layers parece ser un buen punto de partida ya que está relacionado con la mayor variación en los resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construyendo un modelo simple de regresión logística\n",
    "\n",
    "Ahora construiremos y entrenaremos un modelo para predecir la probabilidad de que ocurra una avalancha basándonos únicamente en el número de capas débiles de nieve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we import a function that splits datasets according to a given ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in an 70/30 train/test ratio. \n",
    "train, test = train_test_split(dataset, test_size=0.3, random_state=2)\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acontinuación entrenemos nuestro modelo, usando el conjunto de datos de entrenamiento que acabamos de crear (ten en cuenta que weak_layers será la única característica utilizada para determinar el resultado):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import graphing # custom graphing code. See our GitHub repo for details\n",
    "\n",
    "# Perform logistic regression.\n",
    "model = smf.logit(\"avalanche ~ weak_layers\", train).fit()\n",
    "\n",
    "print(\"Model trained\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de entrenar, podemos imprimir un resumen del modelo con información muy detallada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa que el coeficiente positivo para weak_layers significa que un valor más alto de esta variable se traduce en una mayor probabilidad de que se produzca una avalancha."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando nuestro modelo\n",
    "\n",
    "Ahora podemos utilizar nuestro modelo entrenado para hacer predicciones y estimar probabilidades.\n",
    "\n",
    "Tomemos las primeras cuatro ocurrencias en nuestro conjunto de prueba e imprimamos la probabilidad de una avalancha para cada una de ellas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict to get a probability\n",
    "\n",
    "# get first 3 samples from dataset\n",
    "samples = test[\"weak_layers\"][:4]\n",
    "\n",
    "# use the model to get predictions as possibilities\n",
    "estimated_probabilities = model.predict(samples)\n",
    "\n",
    "# Print results for each sample\n",
    "for sample, pred in zip(samples,estimated_probabilities):\n",
    "    print(f\"A weak_layer with value {sample} yields a {pred * 100:.2f}% chance of an avalanche.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos nuestro modelo para entender esto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "# Show a graph of the result\n",
    "predict = lambda x: model.predict(pandas.DataFrame({\"weak_layers\": x}))\n",
    "\n",
    "graphing.line_2D([(\"Model\", predict)],\n",
    "                 x_range=[-20,40],\n",
    "                 label_x=\"weak_layers\", \n",
    "                 label_y=\"estimated probability of an avalanche\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La línea traza la función de la probabilidad de una avalancha en función del número de capas débiles; observa que cuanto más capas débiles hay, más probable es que ocurra una avalancha. Este gráfico puede parecer un poco confuso por dos razones.\n",
    "\n",
    "En primer lugar, la curva puede hacer predicciones desde menos hasta más infinito, pero solo tenemos datos para 0 a 10 capas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Minimum number of weak layers:\", min(train.weak_layers))\n",
    "print(\"Maximum number of weak layers:\", max(train.weak_layers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se debe a que los modelos de regresión logística permiten hacer predicciones fuera del rango de valores que han visto, y a veces lo hacen bastante bien.\n",
    "\n",
    "La segunda razón por la que el gráfico es confuso es que con 0 capas todavía hay cierto riesgo de avalancha. De manera similar, con 10 capas no hay un riesgo del 100% de avalancha. De hecho, esto está en línea con los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get actual rates of avalanches at 0 years\n",
    "avalanche_outcomes_for_0_layers = train[train.weak_layers == 0].avalanche\n",
    "print(\"Average rate of avalanches for 0 weak layers of snow\", np.average(avalanche_outcomes_for_0_layers))\n",
    "\n",
    "# Get actual rates of avalanches at 10 years\n",
    "avalanche_outcomes_for_10_layers = train[train.weak_layers == 10].avalanche\n",
    "print(\"Average rate of avalanches for 10 weak layers of snow\", np.average(avalanche_outcomes_for_10_layers))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Nuestro modelo en realidad está haciendo un buen trabajo! Es solo que las avalanchas no son causadas únicamente por capas débiles de nieve. Si queremos mejorar, probablemente necesitamos pensar en incluir otra información en el modelo.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La clasificación o los umbrales de decisión\n",
    "\n",
    "Se refieren al valor que se utiliza para determinar si una predicción se considera positiva o negativa. Para devolver una categoría binaria (Verdadero = \"avalancha\", Falso = \"sin avalancha\"), necesitamos definir un valor de umbral de clasificación. Cualquier probabilidad por encima de ese umbral se devolverá como la categoría positiva, mientras que los valores por debajo se devolverán como la categoría negativa.\n",
    "\n",
    "Veamos qué sucede si establecemos nuestro umbral en 0,5 (lo que significa que nuestro modelo devolverá Verdadero siempre que calcule una probabilidad superior al 50% de que ocurra una avalancha):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold to get an absolute value\n",
    "threshold = 0.5\n",
    "\n",
    "# Add classification to the samples we used before\n",
    "for sample, pred in list(zip(samples,estimated_probabilities)):\n",
    "    print(f\"A weak_layer with value {sample} yields a chance of {pred * 100:.2f}% of an avalanche. Classification = {pred > threshold}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten en cuenta que un umbral de 0.5 es solo un punto de partida que debe ajustarse en función de los datos que estamos tratando de clasificar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rendimiento en el conjunto de pruebas\n",
    "\n",
    "Ahora usemos nuestro conjunto de pruebas para realizar una evaluación rápida de cómo lo hizo el modelo. Por ahora, solo veremos cuántas veces predijimos correctamente si habría o no una avalancha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the mdel predictions using the threshold\n",
    "predictions = model.predict(test) > threshold\n",
    "\n",
    "# Compare the predictions to the actual outcomes in the dataset\n",
    "accuracy = np.average(predictions == test.avalanche)\n",
    "\n",
    "# Print the evaluation\n",
    "print(f\"The model correctly predicted outcomes {accuracy * 100:.2f}% of time.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las avalanchas son difíciles de predecir, pero lo estamos haciendo bien. Sin embargo, es difícil saber exactamente qué tipo de errores está cometiendo nuestro modelo. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
